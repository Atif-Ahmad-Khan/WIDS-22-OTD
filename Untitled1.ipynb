{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X5yfNI1wni9z"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import cv2\n",
        "\n",
        "class cv_VideoRead:\n",
        "    def __init__(self,path):\n",
        "        self.path = path        #path of camera source\n",
        "        self.cap=None           #cv2 capture object variable \n",
        "        self.ok = False         #bool to check if frame is read\n",
        "        self.stopped=False      #bool to stop running due to frame read failures\n",
        "        self.tries = 0          #number of retries to grab frame\n",
        "        self.running = False    #bool for main script while loop, run while True\n",
        "\n",
        "    def start(self):\n",
        "        self.cap = cv2.VideoCapture(self.path)\n",
        "        self.running = True if self.cap.isOpened() else False\n",
        "\n",
        "    def stop(self):\n",
        "        if self.stopped:\n",
        "            print (\"[ERROR] Video device could not be read.\")\n",
        "            self.running = False\n",
        "\n",
        "    def get(self):\n",
        "        while(True):\n",
        "            if self.running:\n",
        "                self.ok, self.grab = self.cap.read()\n",
        "                self.tries = 0\n",
        "                self.ok = False\n",
        "                return self.grab\n",
        "            else:\n",
        "                self.tries += 1\n",
        "                self.cap = self.start()\n",
        "                print(\"[MESSAGE] Frame could not be grabbed. Retrying... ({})\".format(str(self.tries)))\n",
        "                if not self.running:\n",
        "                    self.stop()\n",
        "            \n",
        "            if self.tries > 15:\n",
        "                self.stopped = True\n",
        "                self.stop()\n",
        "\n",
        "\n",
        "def set_input_feed(source):\n",
        "    stream=cv_VideoRead(source)\n",
        "    return stream\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from random import randrange as rand\n",
        "\n",
        "def visualise_detections_only(image, detections, labels):\n",
        "    for i in detections:\n",
        "        image = cv2.rectangle(image, (i[0],i[1]), (i[2],i[3]), (255,80,80), 1)\n",
        "        image = cv2.rectangle(image, (i[0],i[1]-12), (i[2],i[1]+4), (200,129,123), -1)\n",
        "        text = labels[i[4]].upper()\n",
        "        image = cv2.putText(image, text, (i[0]+1,i[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (70,70,70), 1, cv2.LINE_AA)\n",
        "    return image \n",
        "\n",
        "def visualise_trackers_only(image, tracked_dets, labels):\n",
        "    for i in tracked_dets:\n",
        "        image = cv2.rectangle(image, (i[0],i[1]), (i[2],i[3]), (20,20,170), 2)\n",
        "        image = cv2.rectangle(image, (i[0]-1,i[1]-12), (i[2]+1,i[1]+4), (rand(90,100),rand(90,100),rand(235,255)), -1)\n",
        "        text = labels[i[4]].upper() + \" | ID:\" + str(i[5]) #check if right order\n",
        "        image = cv2.putText(image, text, (i[0]+1,i[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255,255,255), 1, cv2.LINE_AA)\n",
        "    return image\n",
        "\n",
        "def visualise_counter_only(image, threshold, counter):\n",
        "    frame = cv2.line(image, (threshold, 0),(threshold,int(image.shape[0])),(0,0,255),5)\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    frame = cv2.putText(frame,\n",
        "        \"COUNTER: \" + str(counter), \n",
        "        (5,35), \n",
        "        font, \n",
        "        0.5,\n",
        "        (230,102,30),\n",
        "        2)\n",
        "    return image\n",
        "\n",
        "def show(image, data, labels, fps, frame_count, threshold, counter, SHOW=\"ALL\"):\n",
        "    o_dets = data[0]\n",
        "    t_dets = data[1]\n",
        "\n",
        "    #Visualise FPS first\n",
        "    image = cv2.putText(image, \"FPS: \"+fps, (5,14), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (140, 30, 245), 1, cv2.LINE_AA)\n",
        "\n",
        "    if SHOW != \"ALL\":\n",
        "        if SHOW == \"DETECTED_ONLY\":\n",
        "            image = visualise_detections_only(image, o_dets, labels)\n",
        "            return image\n",
        "        if SHOW == \"TRACKED_ONLY\":\n",
        "            image = visualise_trackers_only(image, t_dets, labels)\n",
        "            return image\n",
        "        if SHOW == \"COUNTER_ONLY\":\n",
        "            image = visualise_counter_only(image, threshold, counter)            \n",
        "        if SHOW == \"\" or SHOW == \"NONE\":\n",
        "            return image\n",
        "    else:\n",
        "        image = visualise_detections_only(image, o_dets, labels)\n",
        "        # if frame_count % 5 == 0: #image saving debug\n",
        "        #     cv2.imwrite(\"tests/exampledet_{}.jpg\".format(str(frame_count)), image)\n",
        "        \n",
        "        image = visualise_trackers_only(image, t_dets, labels)\n",
        "        # if frame_count % 5 == 0: #image saving debug\n",
        "        #     cv2.imwrite(\"tests/exampletrack_{}.jpg\".format(str(frame_count)), image)\n",
        "        \n",
        "        image = visualise_counter_only(image,threshold, counter)\n",
        "        # if frame_count % 5 == 0: #image saving debug\n",
        "        #     cv2.imwrite(\"tests/exampletrack_{}.jpg\".format(str(frame_count)), image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "U9N3vwTgp5GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "DET_SCORE_THRES = 0.77 #0.6-0.75 range #0.75\n",
        "NMS_THRES = 0.77 #0.6-0.8 range #0.70\n",
        "\n",
        "class InitModel:\n",
        "    def __init__(self, INF_GRAPH, LABELMAP):\n",
        "        #~ GPU configuration for inference; attempting to emulate 4 thread (2 core) device\n",
        "        self.config = tf.ConfigProto()\n",
        "        self.config.gpu_options.allow_growth = True\n",
        "        #self.config.log_device_placement = True\n",
        "        #~ Store inference graph and labelmap paths for loading graph and label dictionary\n",
        "        self.INF_GRAPH = INF_GRAPH\n",
        "        self.LABELMAP = LABELMAP\n",
        "\n",
        "\n",
        "    #~ Parse the labelmap file and convert to a dict {key: (int)class_ID; content: (string)label}\n",
        "    def load_labels(self):\n",
        "        labels = {}\n",
        "        with open(self.LABELMAP, \"r\") as fp:\n",
        "            for line in fp:\n",
        "                    if 'id:' in line:\n",
        "                        class_id = int(line.replace(\"id: \",\"\").replace(\"\\n\",\"\").strip(\" \"))\n",
        "                    if 'display_name:' in line:\n",
        "                        displayname = str(line.replace(\"display_name: \",\"\").replace(\"\\n\",\"\").strip(\" \").strip(\"\\\"\"))\n",
        "                        labels[class_id] = displayname\n",
        "        return labels\n",
        "\n",
        "    #~ Import the graph by serialising the binary .pb file with tensorflow functions\n",
        "    def graph_import(self):\n",
        "        detection_graph = tf.Graph()\n",
        "        with detection_graph.as_default():\n",
        "            od_graph_def = tf.compat.v1.GraphDef()\n",
        "            with tf.io.gfile.GFile(self.INF_GRAPH, 'rb') as fid:\n",
        "                serialized_graph = fid.read()\n",
        "                od_graph_def.ParseFromString(serialized_graph)\n",
        "                tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "        self.sess = tf.Session(graph=detection_graph, config=self.config)\n",
        "        return self.sess, detection_graph\n",
        "\n",
        "\n",
        "def non_max_suppression(detections, score_thr, nms_thr):\n",
        "    detections = np.array(detections)\n",
        "\n",
        "    boxes = np.ndarray.tolist(detections[:,:4])\n",
        "    scores = np.ndarray.tolist(detections[:,5])\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, scores, score_thr, nms_thr) \n",
        "    \n",
        "    det_keep = []\n",
        "\n",
        "    for i in indexes:\n",
        "        i = i[0]\n",
        "        det_keep.append(i)\n",
        "\n",
        "    \n",
        "    detections = np.take(detections, (det_keep), axis=0)\n",
        "    return detections\n",
        "\n",
        "def model_inference(sess, image_np, graph, labels):\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "    image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
        "    boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
        "    scores = graph.get_tensor_by_name('detection_scores:0')\n",
        "    classes = graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = graph.get_tensor_by_name('num_detections:0')\n",
        "    #Load all detections\n",
        "    (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections],feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "    #Filter all detections\n",
        "    detections = []\n",
        "    for i in range(len(classes[0])):\n",
        "        if scores[0][i] > DET_SCORE_THRES:#\n",
        "            if classes[0][i].astype(int) == 1:\n",
        "                #~ Load label string for the detection\n",
        "                label = str(labels[classes[0][i].astype(int)])\n",
        "                #~ Un-normalising box coordinates to map to correct frame pixel dims\n",
        "                box_ux = int(boxes[0][i][1]*image_np.shape[1])\n",
        "                box_uy = int(boxes[0][i][0]*image_np.shape[0])\n",
        "                box_bx = int(boxes[0][i][3]*image_np.shape[1])\n",
        "                box_by = int(boxes[0][i][2]*image_np.shape[0])\n",
        "                \n",
        "                coords = [box_ux,box_uy,box_bx,box_by,classes[0][i].astype(int),float(scores[0][i])]\n",
        "\n",
        "                try: detections.append(coords) \n",
        "                except: pass\n",
        "\n",
        "    #NMS for overlapping bounding boxes\n",
        "    if len(detections) > 0:\n",
        "        detections = non_max_suppression(detections, score_thr=DET_SCORE_THRES, nms_thr=NMS_THRES)[:,:5] #remove scores\n",
        "    else:\n",
        "        detections = np.array(detections)\n",
        "\n",
        "    return detections.astype(int)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HmZrHUEKp9cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from trackingfilter import PredictionFilter, TRACKER_LIMIT\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "from math import exp,sqrt\n",
        "\n",
        "#~Tracker globals\n",
        "TRACKER_OBJECTS = {}\n",
        "IOU_THRES = 0.3 #higher = tighter requirements for matching track->det 0.3-0.6 range\n",
        "BOX_OCCL_RATIO_UPD = 0.6 #higher = earlier occlusion probability 0.4=0.7 range\n",
        "BOX_OCCL_RATIO_NEW = 0.6 #likely 0,05-0.02 range\n",
        "SUCCESS_THRES_DEFAULT = 6\n",
        "FAIL_THRES_DEFAULT = 3\n",
        "\n",
        "#~For detection vs tracking comparison of bounding boxes (intersection over union)\n",
        "def IoU(box_a,box_b):\n",
        "    box_a_area = (box_a[2] - box_a[0]+1)*(box_a[3] - box_a[1]+1)\n",
        "    box_b_area = (box_b[2] - box_b[0]+1)*(box_b[3] - box_b[1]+1)\n",
        "    \n",
        "    xA = max(box_a[0], box_b[0])\n",
        "    yA = max(box_a[1], box_b[1])\n",
        "    xB = min(box_a[2], box_b[2])\n",
        "    yB = min(box_a[3], box_b[3])\n",
        "\n",
        "    intersection_area = max(0, xB-xA+1) * max(0, yB-yA+1)\n",
        "    \n",
        "    return intersection_area / float(box_a_area + box_b_area - intersection_area)\n",
        "\n",
        "#~ Using sklearn's implementation of linear assignment to match detections to trackers\n",
        "#~ This uses the Hungarian linear assignment algorithm.\n",
        "def IoU_assign(iou_map):\n",
        "    map_max = np.max(iou_map)\n",
        "    inverted_iou_map = map_max - iou_map\n",
        "\n",
        "    match_idx = linear_assignment(inverted_iou_map)\n",
        "    #match_idx = np.transpose(np.asarray(match_idx))\n",
        "    return match_idx\n",
        "\n",
        "#~ This function updates the measurement noise at tracker update only based on the\n",
        "#~ size of the bounding box (size affects noise)\n",
        "def update_measurement_noise(tracker_obj, curr_det, frame_size):\n",
        "\n",
        "    x = (curr_det[2] - curr_det[0]) * (curr_det[3] - curr_det[1])\n",
        "    x = (x/(frame_size[0]*frame_size[1])) * 100\n",
        "    meas_noise = abs(10*0.002*1.1**x)\n",
        "    tracker_obj.meas_noise = meas_noise\n",
        "    tracker_obj.R = np.diag(tracker_obj.meas_noise*np.ones(4))\n",
        "\n",
        "#~ 6th column of the detection list holds an occlusion metric, when this is -1 (heavy chance of occlusion)\n",
        "#~ the tracker attempts to track by itself instead of updating with detections    \n",
        "def poss_occlusion(curr_det, det_idx, dets, frame_size, BOX_OCCLUSION_RATIO):\n",
        "    \n",
        "    base_point = (int((curr_det[2] + curr_det[0])/2), curr_det[3])\n",
        "    box_width = curr_det[2] - curr_det[0]\n",
        "    hold_tracker = False\n",
        "\n",
        "    #print(\"base point for current detection\", curr_det[2],curr_det[0])\n",
        "\n",
        "    for i in range(len(dets)):\n",
        "        if i != det_idx:\n",
        "            oth_base_point = (int((dets[i,2] + dets[i,0])/2), dets[i,3])\n",
        "\n",
        "            if abs(base_point[0] - oth_base_point[0]) < box_width:\n",
        "                dist = sqrt((base_point[0]-oth_base_point[0])**2 + (base_point[1] - oth_base_point[1])**2)\n",
        "                \n",
        "                if dist < box_width*BOX_OCCLUSION_RATIO:\n",
        "                    hold_tracker = True\n",
        "\n",
        "    return hold_tracker\n",
        "\n",
        "#~ Convert tracker state vectors back to bounding boxes\n",
        "def convert_tvec_to_bbox(vect):\n",
        "    bbox = vect.T[0].tolist()\n",
        "\n",
        "    bbox = bbox[:4]\n",
        "    return bbox\n",
        "\n",
        "\n",
        "#~ Filter trackers at end of each frame, remove trackers which exceed defined thresholds\n",
        "def active_trackers():\n",
        "\n",
        "    trackers_to_record = []\n",
        "    trackers_to_discard = []\n",
        "\n",
        "    for ID in TRACKER_OBJECTS:\n",
        "        tracker = TRACKER_OBJECTS[ID]\n",
        "        if tracker.OK <= tracker.SUCCESS_THRES and tracker.EMPTY >= tracker.FAIL_THRES:\n",
        "            trackers_to_discard.append(ID)\n",
        "        else:\n",
        "            trackers_to_record.append(TRACKER_OBJECTS[ID].COORDS + [TRACKER_OBJECTS[ID].CLASS_ID] + [ID])\n",
        "            \n",
        "\n",
        "    for ID in trackers_to_discard:\n",
        "        TRACKER_OBJECTS.pop(ID, \"[MESSAGE] Tracker object already removed.\")\n",
        "    \n",
        "    return trackers_to_record\n",
        "\n",
        "#~ Assign trackers to detections when there are both previous trackers and current detections\n",
        "def assign_trackers(curr_trackers, curr_detections):\n",
        "        global post_track_record\n",
        "        new_detection_idx = []\n",
        "        empty_trackers_idx = []\n",
        "        match_idx = []\n",
        "        match_idx_to_remove = []\n",
        "\n",
        "        # Assign all trackers to detections based on IOU between bboxes\n",
        "        iou_map = np.zeros([len(curr_trackers), len(curr_detections)])\n",
        "        for t in range(len(curr_trackers)):\n",
        "            for d in range(len(curr_detections)):\n",
        "                iou_map[t,d] = IoU(curr_trackers[t,0], curr_detections[d,:4])\n",
        "\n",
        "        match_idx = IoU_assign(iou_map)\n",
        "\n",
        "        # #*{...\n",
        "        print(\"ID |      R VAL      | SUCCESS:FAILURE | TRACKER(x-1) COORDS  |  DETECTION(x) COORDS  |  IOU VAL\")\n",
        "        for i in range(len(iou_map)):\n",
        "            for j in range(len(iou_map[i])):\n",
        "                print(curr_trackers[i,1],\" | \",TRACKER_OBJECTS[curr_trackers[i,1]].meas_noise,\" | \", TRACKER_OBJECTS[curr_trackers[i,1]].OK, \":\", TRACKER_OBJECTS[curr_trackers[i,1]].EMPTY, \" | \", curr_trackers[i,0], \" | \", curr_detections[j,:4], \" | \", iou_map[i,j],\"\")\n",
        "            print(\"___________________________________________________________\\n\")       \n",
        "        # #*...}\n",
        "\n",
        "        # Check all assignments, if some assignments fall under IOU threshold, remove them\n",
        "        # and add to empty trackers/new detections\n",
        "        for idx, match in enumerate(match_idx):\n",
        "            if (iou_map[match[0],match[1]]) < IOU_THRES:\n",
        "                match_idx_to_remove.append(idx)\n",
        "                empty_trackers_idx.append(match[0])\n",
        "                new_detection_idx.append(match[1])\n",
        "        \n",
        "        # Check for all unassigned indexes, and add to empty trackers/new detections\n",
        "        track_col = match_idx[:,0]\n",
        "        det_col = match_idx[:,1]\n",
        "\n",
        "        for d in range(len(curr_detections)):\n",
        "            if d not in det_col:\n",
        "                new_detection_idx.append(d)\n",
        "\n",
        "        for t in range(len(curr_trackers)):\n",
        "            if t not in track_col:\n",
        "                empty_trackers_idx.append(t)\n",
        "\n",
        "        #Delete all unused matches that were under the IOU threshold\n",
        "        if len(match_idx_to_remove) > 0:\n",
        "            np.delete(match_idx, match_idx_to_remove, axis=0)\n",
        "\n",
        "        return match_idx, new_detection_idx, empty_trackers_idx\n",
        "\n",
        "#~ This function records detections which had no matches/new detections to be stored\n",
        "def assign_unmatched(curr_trackers, curr_detections):\n",
        "    new_detection_idx = []\n",
        "    empty_trackers_idx = []\n",
        "    \n",
        "    for d in range(len(curr_detections)):\n",
        "        new_detection_idx.append(d)\n",
        "\n",
        "    for t in range(len(curr_trackers)):\n",
        "        empty_trackers_idx.append(t)\n",
        "\n",
        "    return new_detection_idx, empty_trackers_idx\n",
        "\n",
        "#~ This function creates tracker objects for new detections which have no previous record\n",
        "def create_tracker(det_idx, curr_detections, frame_size):\n",
        "    detection_coords = curr_detections[det_idx,:4]\n",
        "\n",
        "    new_tracker_obj = PredictionFilter()\n",
        "    \n",
        "    new_id = new_tracker_obj.update_id(TRACKER_OBJECTS) #!!!!\n",
        "\n",
        "    #In the case that all available IDs are full:\n",
        "    if poss_occlusion(detection_coords, det_idx, curr_detections, frame_size, BOX_OCCL_RATIO_NEW) == True or new_id == None:\n",
        "        print(\"[E] Queue full or tracker failed to initialise due to occlusion likelihood.\")\n",
        "        print(poss_occlusion(detection_coords, det_idx, curr_detections, frame_size, BOX_OCCL_RATIO_NEW))\n",
        "        del new_tracker_obj\n",
        "        return False\n",
        "\n",
        "    update_measurement_noise(new_tracker_obj, detection_coords, frame_size)\n",
        "    new_tracker_obj.CLASS_ID = curr_detections[det_idx,4]\n",
        "        \n",
        "    new_tracker_obj.initialise_state_vector_X(detection_coords)\n",
        "    new_tracker_obj.KF_predict()\n",
        "    new_tracker_obj.COORDS = convert_tvec_to_bbox(new_tracker_obj.X)\n",
        "\n",
        "    TRACKER_OBJECTS[new_id] = new_tracker_obj\n",
        "    return True\n",
        "\n",
        "#~ This function updates the tracker object to predict and update for existing trackers\n",
        "def update_tracker(match, curr_detections, curr_trackers, frame_size):        \n",
        "    local_track_idx = match[0]\n",
        "    det_idx = match[1]\n",
        "\n",
        "    detection_coords = curr_detections[det_idx,:4]\n",
        "    tracker_id = curr_trackers[local_track_idx,1]\n",
        "\n",
        "    tracker_obj = TRACKER_OBJECTS[tracker_id]\n",
        "    update_measurement_noise(tracker_obj, detection_coords, frame_size)\n",
        "    \n",
        "\n",
        "    if poss_occlusion(detection_coords, det_idx, curr_detections, frame_size, BOX_OCCL_RATIO_UPD):\n",
        "        tracker_obj.KF_predict()\n",
        "        tracker_obj.EMPTY = 0\n",
        "        tracker_obj.OK += 1\n",
        "        #print(\"tracker_id: \", tracker_id, \"apparent occlusion\")\n",
        "\n",
        "    else:\n",
        "        tracker_obj.FAIL_THRES = FAIL_THRES_DEFAULT\n",
        "        tracker_obj.SUCCESS_THRES = SUCCESS_THRES_DEFAULT\n",
        "        tracker_obj.initialise_meas_vector_Z(detection_coords)\n",
        "        tracker_obj.KF_predict_and_track()\n",
        "        tracker_obj.EMPTY = 0\n",
        "        tracker_obj.OK += 1\n",
        "\n",
        "    tracker_obj.COORDS = convert_tvec_to_bbox(tracker_obj.X)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "#~ This function manages empty trackers with no matched detections, adding to the thresholds\n",
        "#~ for these\n",
        "def manage_empty_tracker(track_idx, curr_trackers):\n",
        "    local_track_idx = track_idx\n",
        "    tracker_id = curr_trackers[local_track_idx,1]\n",
        "\n",
        "    tracker_obj = TRACKER_OBJECTS[tracker_id]\n",
        "    tracker_obj.EMPTY += 1\n",
        "    tracker_obj.OK = 0 #! changed from total 0 to subtract one each time\n",
        "\n",
        "    tracker_obj.KF_predict()\n",
        "    tracker_obj.COORDS = convert_tvec_to_bbox(tracker_obj.X)\n",
        "\n",
        "#~ Main tracking pipeline, filtering incoming data for existing, new and missing trackers\n",
        "#~ by linear assignment of bounding boxes to update filter measurements, and assigning new\n",
        "#~ tracking IDs to the system, and use the filter to update.\n",
        "\n",
        "def tracking_handler(curr_detections, frame_size):\n",
        "    #Initialise essential variables\n",
        "\n",
        "    curr_trackers = []\n",
        "    new_detection_idx = []\n",
        "    empty_trackers_idx = []\n",
        "    match_idx = []\n",
        "\n",
        "    for tobj in TRACKER_OBJECTS:\n",
        "        curr_trackers.append([TRACKER_OBJECTS[tobj].COORDS, TRACKER_OBJECTS[tobj].ID])\n",
        "\n",
        "    curr_trackers = np.array(curr_trackers)\n",
        "    \n",
        "    ignore_new_detections = True if len(TRACKER_OBJECTS) == TRACKER_LIMIT else False\n",
        "\n",
        "    if len(curr_trackers) > 0 and len(curr_detections) > 0:\n",
        "        match_idx, new_detection_idx, empty_trackers_idx = assign_trackers(curr_trackers, curr_detections)\n",
        "    else:\n",
        "        new_detection_idx, empty_trackers_idx = assign_unmatched(curr_trackers, curr_detections)\n",
        "\n",
        "    for match in match_idx:\n",
        "        update_tracker(match, curr_detections, curr_trackers, frame_size)\n",
        "\n",
        "    if ignore_new_detections == False:\n",
        "        for idxD in new_detection_idx:\n",
        "            success = create_tracker(idxD, curr_detections, frame_size)\n",
        "            if success == False: break\n",
        "\n",
        "    for idxT in empty_trackers_idx:\n",
        "        manage_empty_tracker(idxT, curr_trackers)\n",
        "\n",
        "    return active_trackers()\n",
        "    "
      ],
      "metadata": {
        "id": "4bYhwVbDqDZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from filterpy.common import Q_discrete_white_noise\n",
        "from numpy.testing._private.utils import measure\n",
        "from scipy import linalg\n",
        "\n",
        "SUCCESS_THRES_DEFAULT = 5\n",
        "FAIL_THRES_DEFAULT = 2\n",
        "\n",
        "TRACKER_LIMIT = 100\n",
        "\n",
        "class PredictionFilter():\n",
        "    def __init__(self):\n",
        "        #~ Tracking ID\n",
        "        self.ID = None\n",
        "\n",
        "        #~ Tracked box coordinates\n",
        "        self.COORDS = []\n",
        "        \n",
        "        #~ Information about the tracked box (from detection)\n",
        "        self.CLASS_ID = 0\n",
        "\n",
        "        #~ OK: Number of consecutive matched runs, EMPTY: Number of consecutive unmatched runs\n",
        "        #~ Making the fail and success thres specific to the tracker \n",
        "        self.SUCCESS_THRES = SUCCESS_THRES_DEFAULT #how many times the tracker has to succeed to appear 4-6 range\n",
        "        self.FAIL_THRES = FAIL_THRES_DEFAULT #how many times the tracker can miss without losing 1-3 range\n",
        "\n",
        "        self.OK = 0\n",
        "        self.EMPTY = 0\n",
        "\n",
        "        #~ Kalman filter calculation parameters \n",
        "        #  (state = input measurement state, dt = time interval)\n",
        "        self.X = [] #~ State vector X*\n",
        "        self.Z = [] #~ Measurement vector Z*\n",
        "\n",
        "        self.dt = 0.05\n",
        "\n",
        "        #~ State transition matrix F initialisation\n",
        "        #  This is used to update covariance and measurement matrices based on \n",
        "        #  elapsed time. The time derivative only calculated for position\n",
        "        # as this is a constant velocity model. (assume negligible acceleration)\n",
        "        self.F = np.identity(8)\n",
        "        for i in range(4):\n",
        "            self.F[i,i+4] = self.dt\n",
        "\n",
        "        # STATE TRANSITION MATRIX:  --is used during tracking\n",
        "        # [1,  0,  0,  0,  dt,  0,  0, 0 ]\n",
        "        # [0,  1,  0,  0,  0,  dt, 0,  0 ]\n",
        "        # [0,  0,  1,  0,  0,  0,  dt, 0 ]\n",
        "        # [0,  0,  0,  1,  0,  0,  0,  dt]\n",
        "        # [0,  0,  0,  0,  1,  0,  0,  0 ]\n",
        "        # [0,  0,  0,  0,  0,  1,  0,  0 ]\n",
        "        # [0,  0,  0,  0,  0,  0,  1,  0 ]\n",
        "        # [0,  0,  0,  0,  0,  0,  0,  1 ]\n",
        "\n",
        "        #~ Process covariance matrix Q, models the noise behaviour of the system (error)\n",
        "        #  Note this is a covariance matrix hence symmetric positive-demidefinite\n",
        "        #  Base assumption: Noise is modeled as a discrete wiener process over time,\n",
        "        #  Hence, noise is assumed as Gaussian and random, on average constant over time\n",
        "\n",
        "        # Possible to do live velocity mapping, check accuracy of movement bbox maps\n",
        "        # Note- is noise in det vs track independent? when more people, need more precision\n",
        "        self.noise_var1 = 0.05\n",
        "        self.noise_var2 = 0.1\n",
        "        self.noise1 = Q_discrete_white_noise(dim=2, dt=self.dt, var=self.noise_var1)\n",
        "        self.noise2 = Q_discrete_white_noise(dim=2, dt=self.dt, var=self.noise_var2)\n",
        "\n",
        "        self.Q = linalg.block_diag(self.noise1, self.noise2, \n",
        "                                   self.noise2, self.noise1)\n",
        "        \n",
        "        #PROCESS NOISE COVARIANCE MATRIX --is manipulated during tracking\n",
        "\n",
        "        # [0.01 0.01.0.   0.   0.   0.   0.   0.   ]\n",
        "        # [0.01 0.01.0.   0.   0.   0.   0.   0.   ]\n",
        "        # [0.   0.   0.01 0.01 0.   0.   0.   0.   ]\n",
        "        # [0.   0.   0.01 0.01.0.   0.   0.   0.   ]\n",
        "        # [0.   0.   0.   0.   0.01.0.01.0.   0.   ]\n",
        "        # [0.   0.   0.   0.   0.01.0.01.0.   0.   ]\n",
        "        # [0.   0.   0.   0.   0.   0.   0.01.0.01.]\n",
        "        # [0.   0.   0.   0.   0.   0.   0.01.0.01.]\n",
        "\n",
        "        #~ Process (uncertainty) state covariance matrix P\n",
        "        # This is initialised at a relatively small value (e.g. 10) and will grow to variance\n",
        "        # in state (position) estimations with error measurements of bounding boxes, using the\n",
        "        # Q matrix.\n",
        "\n",
        "        self.uncertainty = 10.0\n",
        "        self.P  = np.diag(self.uncertainty*np.ones(8))\n",
        "\n",
        "        # PROCESS STATE COVARIANCE MATRIX --is manipulated during tracking\n",
        "        # [10,  0,  0,  0,  0,  0,  0,  0 ]\n",
        "        # [0,  10,  0,  0,  0,  0,  0,  0 ]\n",
        "        # [0,  0,  10,  0,  0,  0,  0,  0 ]\n",
        "        # [0,  0,  0,  10,  0,  0,  0,  0 ]\n",
        "        # [0,  0,  0,  0,  10,  0,  0,  0 ]\n",
        "        # [0,  0,  0,  0,  0,  10,  0,  0 ]\n",
        "        # [0,  0,  0,  0,  0,  0,  10,  0 ]\n",
        "        # [0,  0,  0,  0,  0,  0,  0,  10 ]\n",
        "\n",
        "        #~ Measurement matrix H, helper matrix for matrix calculations\n",
        "        # This matrix helps transform the format of matrix P such that it can be evaluated\n",
        "        # for matrix K (later shown), the Kalman gain, and is dependent on our input vector \n",
        "        # dimensions, x=8 (cols) and y=4 (rows)\n",
        "\n",
        "        self.H = np.concatenate([np.identity(4),np.zeros([4,4])], axis=1)\n",
        "        \n",
        "        # MEASUREMENT MATRIX --is initialised on measurement\n",
        "        # [1, 0, 0, 0, 0, 0, 0, 0]\n",
        "        # [0, 1, 0, 0, 0, 0, 0, 0]\n",
        "        # [0, 0, 1, 0, 0, 0, 0, 0]\n",
        "        # [0, 0, 0, 1, 0, 0, 0, 0]\n",
        "\n",
        "        #~ Measurement noise matrix R, works out the noise from input on measurement\n",
        "        # This can also be seen as the deviation in a still bounding box over time\n",
        "        # which can be modelled as measurement noise, we can assume this is closer\n",
        "        # to about 1 pixel for highly accurate models, up to 10-20 pixels for weaker\n",
        "        # models with minor detection fluctuations. I'll start with 1.\n",
        "\n",
        "        self.meas_noise = 1e-3\n",
        "        self.R = np.diag(self.meas_noise*np.ones(4))\n",
        "\n",
        "        # MEASUREMENT NOISE MATRIX --can be updated on measurement\n",
        "        # [1, 0, 0, 0]\n",
        "        # [0, 1, 0, 0]\n",
        "        # [0, 0, 1, 0]\n",
        "        # [0, 0, 0, 1]\n",
        "\n",
        "        #~ *Measurement vector Z: This is initialised when an object is detected,\n",
        "        #  and utiises only the measurement coordinates, as velocity is not known\n",
        "        #  on first pass. \n",
        "        \n",
        "        #  MEASUREMENT VECTOR Z: [cx, cy, w, h]\n",
        "\n",
        "        #~ *Measurement vector X: This is adjusted at each step, and is synchronised\n",
        "        #~ with detections.\n",
        "        #  This is defined as the position and velocity constants at each step, for a\n",
        "        #  constant velocity vector. Velocities are initialised as 0 each time.\n",
        "        \n",
        "        #  MEASUREMENT VECTOR X: [cx, cy, w, h, v1(0), v2(0), v3(0), v4(0)]\n",
        "        \n",
        "    #*{...CHECK IF THIS FUNCTION IS DOING THE RIGHT THING}\n",
        "    def update_id(self, TRACKER_OBJECTS):\n",
        "        #~ IDs range from 0 to 99, == keys in TRACKER_OBJECTS, assign\n",
        "        #~ new IDs by free values in this range, prioritising smallest.\n",
        "        \n",
        "        # If there is nothing in TRACKER_OBJECTS, this ID will be 0\n",
        "        if len(TRACKER_OBJECTS) == TRACKER_LIMIT:\n",
        "            self.ID = None\n",
        "        if len(TRACKER_OBJECTS) == 0: \n",
        "            self.ID = 0 \n",
        "        else: \n",
        "            # then the current ID is the highest ID + 1 (will be unused)\n",
        "            self.ID = max(TRACKER_OBJECTS.keys()) + 1       \n",
        "\n",
        "        return self.ID\n",
        "\n",
        "    def initialise_state_vector_X(self, bbox):\n",
        "        #~ Assume a constant velocity model and initialise with v=0\n",
        "        #~ Convert bbox state to Kalman filter state: [x1,y1,x2,y2...\n",
        "\n",
        "        position_state = [bbox[0], bbox[1], bbox[2], bbox[3]]\n",
        "        #~ And add the velocity states, initialised as 0, auto-estimated on each step\n",
        "        velocity_state = [0,0,0,0]\n",
        "        #~Return as a numpy array for matrix calculations: (column vector format)\n",
        "        state_vector = np.array(position_state + velocity_state)\n",
        "        state_vector = np.expand_dims(state_vector, axis = 0)\n",
        "        state_vector = state_vector.T\n",
        "\n",
        "        self.X = state_vector\n",
        "\n",
        "    def initialise_meas_vector_Z(self, bbox):\n",
        "        #~ The measurement vector has the initial state, this is static and hence\n",
        "        #~ velocity is not added to the vector.\n",
        "\n",
        "        #~Return as a numpy array for matrix calculations: (column vector format)\n",
        "        msr_vector = np.array([bbox[0], bbox[1], bbox[2], bbox[3]])\n",
        "        msr_vector = np.expand_dims(msr_vector, axis=0)\n",
        "        msr_vector = msr_vector.T \n",
        "\n",
        "        self.Z = msr_vector\n",
        "\n",
        "    def KF_predict_and_track(self):\n",
        "        #~ Predict next time step: Deriving state predictions using the state transition matrix\n",
        "\n",
        "        # X(t) = F.X(t-1)\n",
        "        X_pred = np.dot(self.F, self.X)\n",
        "\n",
        "        # P(t) = F.P(t-1).F^T\n",
        "        P_pred = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
        "\n",
        "        # Update current stage:\n",
        "\n",
        "        #~ Kalman gain (K): Essentially calculating error in estimate vs error in the\n",
        "        #~ measurement, putting more weight on the smaller error \n",
        "        \n",
        "        # K = (P(t).H^T) / (H.P.H^T + R)\n",
        "        K_gain = np.dot(P_pred,self.H.T).dot(linalg.inv(np.dot(self.H,P_pred).dot(self.H.T) + self.R))\n",
        "        \n",
        "        #~ Performing X state updating, predicted X value gets filtered by actual measurement\n",
        "        #~ subtracted with predicted X, and added to existing value to get updated X value.\n",
        "        #~ And updating process covariance matrix. \n",
        "\n",
        "        # X(t) = X(t) + K.(Z(t) - H.X(t))\n",
        "        self.X = (X_pred + np.dot(K_gain,(self.Z - np.dot(self.H,X_pred)))).astype(int)\n",
        "        \n",
        "        # P(t) = (K.H).P(t)\n",
        "        self.P = -(np.dot(K_gain, self.H)).dot(self.P)\n",
        "\n",
        "        #Then, X(t-1) = X(t) and P(t-1) = P(t) and the system can be re-evaluated\n",
        "\n",
        "    def KF_predict(self):\n",
        "        #~ Predict next time step: Deriving state predictions using the state transition matrix\n",
        "        # We only run prediction when the previous state is unknown\n",
        "\n",
        "        X_pred = np.dot(self.F, self.X)\n",
        "        P_pred = np.dot(self.F, self.P).dot(self.F.T) + self.Q\n",
        "\n",
        "        self.X = X_pred.astype(int)\n",
        "        self.P = P_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "xtrPELRQqH1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "import objectdetector\n",
        "import videostream\n",
        "import visualiser\n",
        "from objectdetector import InitModel\n",
        "from tracker import tracking_handler\n",
        "\n",
        "sys.path.append(\"../Backend/\")\n",
        "\n",
        "#*TEST BLOCK {...} \n",
        "\n",
        "#~Camera feed globals\n",
        "VIDEO_SOURCE = 0 #0\n",
        "\n",
        "FRAME_INPUT_DIMS = (720,405)\n",
        "\n",
        "#~Object detection inference globals\n",
        "#INF_GRAPH='ssd_inception_v2_coco_2018_01_28/frozen_inference_graph.pb' #*det_thres=0.35, nms_thres=0.8, tracker:0.2,0.7,0.2,5,4, R scalar *100 (much more noise)\n",
        "INF_GRAPH = 'inceptionv2frcnn/frozen_inference_graph.pb' #*det_thres=0.75, nms_thres=0.75, tracker:0.3,0.6,0.5,5,2\n",
        "\n",
        "LABELMAP='labelmap.pbtxt'\n",
        "\n",
        "def write_data(frame, data):\n",
        "    timestamp = str(datetime.now())\n",
        "    output_string = timestamp + \">> \" + str(data) + \"\\n\"\n",
        "    return output_string\n",
        "\n",
        "def main():\n",
        "    #~ Initialise deep learning model to detect objects\n",
        "    modelinfo = InitModel(INF_GRAPH, LABELMAP)\n",
        "    labels = modelinfo.load_labels()\n",
        "    sess,det_graph = modelinfo.graph_import()\n",
        "\n",
        "    #~ Initialise video stream\n",
        "    frame_count = 0 #debug\n",
        "    stream = videostream.set_input_feed(VIDEO_SOURCE)\n",
        "    \n",
        "    stream.start()\n",
        "\n",
        "    #~ Start main loop for constant detection and tracking\n",
        "    while(stream.running):\n",
        "        #~ Get current active frame\n",
        "        fps_a = time.time()\n",
        "\n",
        "        frame = stream.get()\n",
        "        frame = cv2.resize(frame, (FRAME_INPUT_DIMS[0], int(FRAME_INPUT_DIMS[1])))\n",
        "\n",
        "        #~ Get detections off the current frame\n",
        "        detections = objectdetector.model_inference(sess, frame, det_graph, labels)        \n",
        "        print(\"Number of initial detections: \", len(detections))\n",
        "\n",
        "        #~ Track these detections \n",
        "        tracked_detections = tracking_handler(detections, FRAME_INPUT_DIMS)\n",
        "        print(\"Number of currently tracked detections: \", len(tracked_detections))\n",
        "\n",
        "        #~ Data transfer function\n",
        "        output_string = write_data(frame, tracked_detections)\n",
        "\tprint(output_string)\n",
        "\n",
        "        #~ Calculate FPS\n",
        "        fps_b = time.time() \n",
        "        fps = str(round(1/(fps_b - fps_a),2))\n",
        "\n",
        "        #~ Display debug function for the bounding boxes with labels and person ID\n",
        "        # To show only detections add optional argument SHOW=\"DETECTED_ONLY\"\n",
        "        # or for trackers \"TRACKED_ONLY\", or for only counter, \"COUNTER_ONLY\",\n",
        "        # to show nothing add empty string \"\" or \"NONE\"\n",
        "        frame = visualiser.show(\n",
        "            frame, \n",
        "            [detections,tracked_detections], \n",
        "            labels, \n",
        "            fps, \n",
        "            frame_count,\n",
        "            threshold,\n",
        "            counter, \n",
        "            SHOW=\"ALL\")\n",
        "\n",
        "        #~ Show frame\n",
        "        cv2.imshow(\"debug feed\", frame)\n",
        "\n",
        "        frame_count += 1 #debug\n",
        "        \n",
        "        if cv2.waitKey(25) and 0xFF == ord('q'):  #put back\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    sess.close()\n",
        "    exit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJ590aRKqRVt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}